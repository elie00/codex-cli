/**
 * Fichier de traduction fran√ßais pour codex-cli
 * Ce fichier centralise toutes les cha√Ænes de caract√®res de l'interface
 */

// Types pour les traductions
type TranslationGroups = {
  common: Record<string, string>;
  errors: Record<string, string>;
  cli: Record<string, string>;
  interface: Record<string, string>;
  providers: Record<string, string>;
  splashScreen: Record<string, string>;
  help: Record<string, string>;
  model_selection: Record<string, string>;
};

/**
 * Traductions fran√ßaises
 */
const fr: TranslationGroups = {
  // Termes communs utilis√©s dans toute l'application
  common: {
    // Noms des fournisseurs
    'provider_openai': 'OpenAI',
    'provider_ollama': 'Ollama',
    'provider_huggingface': 'HuggingFace',
    
    // Modes d'approbation
    'approval_suggest': 'suggestion',
    'approval_auto_edit': '√©dition auto',
    'approval_full_auto': 'auto complet',
    
    // Termes g√©n√©raux
    'loading': 'Chargement...',
    'cancel': 'Annuler',
    'confirm': 'Confirmer',
    'yes': 'Oui',
    'no': 'Non',
    'ok': 'OK',
    'error': 'Erreur',
    'warning': 'Attention',
    'info': 'Info',
    'success': 'Succ√®s',
    'default_prompt': 'Bonjour, pouvez-vous m\'aider ?',
    
    // Messages de chargement vari√©s
    'thinking': 'R√©flexion en cours...',
    'processing': 'Traitement en cours...',
    'analyzing': 'Analyse en cours...',
    'generating': 'G√©n√©ration en cours...',
    'writing': 'R√©daction en cours...',
    'coding': 'Programmation en cours...',
    
    // Touches de raccourci
    'press_enter': 'Appuyez sur Entr√©e',
    'press_esc': 'Appuyez sur √âchap',
    'press_tab': 'Appuyez sur Tab',
  },
  
  // Messages pour l'√©cran de s√©lection de mod√®le
  model_selection: {
    'title': 'S√©lection du mod√®le Ollama',
    'instructions': 'Choisissez le mod√®le que vous souhaitez utiliser pour cette session.',
    'local_models': 'Mod√®les locaux',
    'popular_models': 'Mod√®les populaires',
    'no_local_models': 'Aucun mod√®le local trouv√©. Utilisez la commande "ollama pull <mod√®le>" pour en t√©l√©charger.',
    'no_popular_models': 'Aucun mod√®le populaire disponible actuellement.',
    'loading': 'Chargement des mod√®les...',
    'help': 'Appuyez sur {toggle} pour basculer entre les mod√®les locaux/populaires, {select} pour naviguer, {confirm} pour s√©lectionner, {cancel} pour annuler',
    'params': 'Param√®tres pour {model}: {params}',
    'model_selected': 'Mod√®le {model} s√©lectionn√©!',
    'install_model': 'Installer ce mod√®le',
    'already_installed': 'D√©j√† install√©',
    'current_model': 'Mod√®le actuel',
    'downloading': 'T√©l√©chargement du mod√®le {model}...',
    'download_success': 'Mod√®le {model} t√©l√©charg√© avec succ√®s!',
    'download_error': 'Erreur lors du t√©l√©chargement du mod√®le {model}',
  },
  
  // Messages d'erreur
  errors: {
    // Erreurs g√©n√©rales
    'generic_error': 'Une erreur est survenue. Veuillez r√©essayer.',
    'network_error': '‚ö†Ô∏è  Erreur r√©seau lors de la communication avec le fournisseur LLM. Veuillez v√©rifier votre connexion et r√©essayer.',
    'timeout_error': '‚ö†Ô∏è  D√©lai d\'attente d√©pass√©. Veuillez r√©essayer.',
    'provider_error': '‚ö†Ô∏è  Erreur du fournisseur LLM. Veuillez r√©essayer.',
    'api_key_missing': '‚ö†Ô∏è  Cl√© API manquante. Veuillez configurer votre cl√© API.',
    
    // Erreurs sp√©cifiques √† OpenAI
    'openai_api_key_missing': `
‚ö†Ô∏è  Cl√© API OpenAI manquante.

D√©finissez la variable d'environnement OPENAI_API_KEY et red√©marrez cette commande.
Vous pouvez cr√©er une cl√© ici: https://platform.openai.com/account/api-keys
`,
    'openai_rate_limit': '‚ö†Ô∏è  Limite de d√©bit OpenAI atteinte. Veuillez r√©essayer plus tard.',
    'openai_context_length': '‚ö†Ô∏è  La requ√™te actuelle d√©passe la longueur de contexte maximale support√©e par le mod√®le choisi. Veuillez raccourcir la conversation, ex√©cuter /clear, ou passer √† un mod√®le avec une fen√™tre de contexte plus grande et r√©essayer.',
    
    // Erreurs sp√©cifiques √† Ollama
    'ollama_connection_error': '‚ö†Ô∏è  Impossible de se connecter au serveur Ollama. V√©rifiez que le serveur est en cours d\'ex√©cution.',
    'ollama_model_not_found': '‚ö†Ô∏è  Mod√®le Ollama non trouv√©. Veuillez v√©rifier le nom du mod√®le ou t√©l√©charger le mod√®le avec "ollama pull NOM_DU_MODELE".',
    'ollama_error': '‚ö†Ô∏è  Erreur Ollama. Veuillez v√©rifier que le serveur est en cours d\'ex√©cution et que le mod√®le est disponible.',
    
    // Erreurs li√©es au mod√®le
    'model_not_supported': '‚ö†Ô∏è  Le mod√®le "{model}" n\'appara√Æt pas dans la liste des mod√®les disponibles pour le fournisseur {provider}.\nVeuillez v√©rifier le nom du mod√®le et r√©essayer.',
    'model_load_error': '‚ö†Ô∏è  Erreur lors du chargement du mod√®le. Veuillez r√©essayer.',
    
    // Erreurs d'ex√©cution
    'execution_interrupted': '‚èπÔ∏è  Ex√©cution interrompue par l\'utilisateur.',
    'command_error': '‚ö†Ô∏è  Erreur lors de l\'ex√©cution de la commande. Code de sortie: {code}',
    'stream_closed': '‚ö†Ô∏è  La connexion s\'est ferm√©e pr√©matur√©ment en attendant le mod√®le. Veuillez r√©essayer.',
  },
  
  // Messages de ligne de commande
  cli: {
    // Usage et aide
    'usage': `
  Utilisation
    $ codex [options] <prompt>
    $ codex completion <bash|zsh|fish>

  Options
    -h, --help                 Afficher l'aide et quitter
    -m, --model <model>        Mod√®le √† utiliser (d√©faut: gemma3:4b)
    -i, --image <path>         Chemin(s) vers des fichiers image √† inclure
    -v, --view <rollout>       Inspecter un rollout pr√©c√©demment sauvegard√©
    -q, --quiet                Mode non-interactif (affiche seulement la sortie finale)
    -c, --config               Ouvrir le fichier d'instructions dans votre √©diteur
    -a, --approval-mode <mode> Remplacer la politique d'approbation: 'suggest', 'auto-edit', ou 'full-auto'

    --auto-edit                Approuver automatiquement les √©ditions de fichiers; demander pour les commandes
    --full-auto                Approuver automatiquement les √©ditions et commandes dans le bac √† sable

    --no-project-doc           Ne pas inclure automatiquement le 'codex.md' du d√©p√¥t
    --project-doc <file>       Inclure un fichier markdown additionnel comme contexte
    --full-stdout              Ne pas tronquer la sortie stdout/stderr des commandes

    --provider <provider>      Fournisseur LLM √† utiliser ('openai', 'ollama', ou 'huggingface') (d√©faut: ollama)
    --provider-url <url>       URL de l'API du fournisseur (pour Ollama et HuggingFace)

  Options dangereuses
    --dangerously-auto-approve-everything
                               Ignorer toutes les demandes de confirmation et ex√©cuter les commandes sans
                               bac √† sable. Uniquement destin√© aux tests locaux √©ph√©m√®res.

  Options exp√©rimentales
    -f, --full-context         Lancer en mode "contexte complet" qui charge l'ensemble du d√©p√¥t
                               dans le contexte et applique un lot de modifications en une fois.

  Exemples
    $ codex "√âcrire et ex√©cuter un programme Python qui affiche de l'art ASCII"
    $ codex -q "Corriger les probl√®mes de build"
    $ codex completion bash
    $ codex --provider ollama --model llama3 "√©cris une fonction qui calcule fibonacci"
`,
    
    // Exemples et suggestions
    'example_1': 'Explique-moi ce code',
    'example_2': 'Corrige les erreurs de compilation',
    'example_3': 'Y a-t-il des bugs dans mon code?',
    'example_4': '√âcris un programme qui affiche de l\'art ASCII',
    'example_5': 'Optimise cette fonction',
    
    // Messages divers de CLI
    'missing_prompt': 'Le mode silencieux n√©cessite une cha√Æne prompt, ex.: codex -q "Corriger le bug #123 dans le projet foobar"',
    'initializing': 'Initialisation de l\'agent...',
    'completion_unsupported_shell': 'Shell non support√©: {shell}',
  },
  
  // Messages d'interface
  interface: {
    // Header et informations de session
    'header_title': 'Codex',
    'header_subtitle': 'assistant de code',
    'session_info': 'session: {id}',
    'workdir': 'workdir: {path}',
    'provider': 'fournisseur: {provider}',
    'model': 'mod√®le: {model}',
    'approval': 'approbation: {mode}',
    
    // Messages d'interface
    'input_placeholder': 'Envoyer un message ou Tab pour une suggestion',
    'send_message': 'Envoyer',
    'cancel_request': 'Annuler la requ√™te',
    'git_warning_title': 'Attention !',
    'git_warning_message': 'Il peut √™tre dangereux d\'ex√©cuter un agent de codage en dehors d\'un d√©p√¥t git, car vous ne pourrez pas annuler facilement les modifications. Voulez-vous continuer ?',
    
    // Messages de fonctionnalit√©s
    'command_review': 'R√©vision de commande',
    'execute_command': 'Ex√©cuter cette commande ?',
    'approve': 'Approuver',
    'deny': 'Refuser',
    'skip': 'Ignorer',
    'loading_status': '{seconds}s √©coul√©es',
    'context_remaining': 'Contexte restant: {percent}%',
    
    // Overlays
    'history_title': 'Historique',
    'model_selection_title': 'S√©lection du mod√®le',
    'model_switch': 'Chang√© de mod√®le vers {model}',
    'approval_mode_title': 'Mode d\'approbation',
    'approval_switch': 'Chang√© de mode d\'approbation vers {mode}',
  },
  
  // Messages li√©s aux fournisseurs LLM
  providers: {
    'ollama_connecting': 'Connexion √† Ollama...',
    'ollama_connected': 'Connexion √† Ollama √©tablie avec succ√®s: {url}',
    'ollama_streaming': 'D√©marrage de la r√©ponse en streaming',
    'ollama_request': 'Requ√™te Ollama - Mod√®le: {model}',
    'ollama_models_available': 'Mod√®les Ollama disponibles: {models}',
    'ollama_model_info': 'Informations sur le mod√®le: {info}',
    
    'openai_models_available': 'Mod√®les OpenAI disponibles: {models}',
    'openai_request': 'Requ√™te OpenAI - Mod√®le: {model}',
    
    'huggingface_connecting': 'Connexion √† HuggingFace...',
    'huggingface_models_available': 'Mod√®les HuggingFace disponibles: {models}',
  },
  
  // Messages de l'√©cran d'accueil
  splashScreen: {
    'welcome': '* Bienvenue dans votre assistant de code',
    'loading': 'Initialisation... {percent}%',
    'ready': 'Pr√™t !',
    'login_success': 'üöÄ Connexion r√©ussie. Appuyez sur ',
    'enter_to_continue': 'Entr√©e',
    'to_continue': ' pour continuer',
    'version': 'Version {version}',
    'provider_info': 'Fournisseur: {provider} | Mod√®le: {model}',
  },
  
  // Messages d'aide
  help: {
    'title': 'Aide Codex',
    'subtitle': 'Raccourcis et commandes',
    'shortcuts_title': 'Raccourcis clavier',
    'commands_title': 'Commandes',
    
    'shortcut_esc': '√âchap',
    'shortcut_esc_desc': 'Annuler la requ√™te en cours / Quitter l\'overlay',
    'shortcut_enter': 'Entr√©e',
    'shortcut_enter_desc': 'Envoyer le message / Confirmer',
    'shortcut_tab': 'Tab',
    'shortcut_tab_desc': 'Afficher les suggestions',
    'shortcut_arrows': 'Fl√®ches Haut/Bas',
    'shortcut_arrows_desc': 'Naviguer dans l\'historique des messages',
    'shortcut_ctrl_c': 'Ctrl+C',
    'shortcut_ctrl_c_desc': 'Quitter Codex',
    
    'command_help': '/help',
    'command_help_desc': 'Afficher cette aide',
    'command_clear': '/clear',
    'command_clear_desc': 'Effacer l\'historique de la conversation',
    'command_model': '/model',
    'command_model_desc': 'Changer de mod√®le',
    'command_mode': '/mode',
    'command_mode_desc': 'Changer de mode d\'approbation',
    'command_ollama': '/ollama',
    'command_ollama_desc': 'Configurer les param√®tres Ollama',
    'command_models': '/models',
    'command_models_desc': 'G√©rer les mod√®les Ollama',
  },
};

/**
 * Fonction pour obtenir une traduction
 * @param key Cl√© de traduction sous forme 'groupe.cl√©'
 * @param params Param√®tres optionnels pour les substitutions
 */
export function translate(key: string, params?: Record<string, string | number>): string {
  const [group, subKey] = key.split('.');
  
  if (!group || !subKey) {
    console.warn(`Cl√© de traduction invalide: ${key}`);
    return key;
  }
  
  // V√©rifier si le groupe existe
  if (!(group in fr)) {
    console.warn(`Groupe de traduction inconnu: ${group}`);
    return key;
  }
  
  // Obtenir le texte traduit
  const translationGroup = fr[group as keyof TranslationGroups];
  const translated = translationGroup[subKey];
  
  if (!translated) {
    console.warn(`Cl√© de traduction inconnue: ${key}`);
    return key;
  }
  
  // Remplacer les param√®tres si n√©cessaire
  if (params) {
    return Object.entries(params).reduce(
      (text, [paramKey, paramValue]) => 
        text.replace(new RegExp(`{${paramKey}}`, 'g'), String(paramValue)),
      translated
    );
  }
  
  return translated;
}

// Alias pour simplifier l'utilisation
export const t = translate;

// Exporter le dictionnaire et la fonction
export default { fr, translate, t };
